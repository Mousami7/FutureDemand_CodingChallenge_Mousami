{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b77a466",
   "metadata": {},
   "source": [
    "## Importing necessary libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # Importing the requests library to make HTTP requests\n",
    "from bs4 import BeautifulSoup  # Importing BeautifulSoup for HTML parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3482a29",
   "metadata": {},
   "source": [
    "## Scrape the data from the link provided and extract the event details and iterate over each and every event description from html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc65bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.lucernefestival.ch/en/program/summer-festival-24\"  # URL of the webpage to scrape provided in the coding challenge\n",
    "\n",
    "# Fetch the HTML content from the URL\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "\n",
    "# Function to extract event details\n",
    "def extract_event_details(soup):\n",
    "    \"\"\"\n",
    "    Extract event details from the BeautifulSoup object.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): The BeautifulSoup object containing parsed HTML content.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing event details.\n",
    "    \"\"\"\n",
    "    event_details = []  # List to store extracted event details\n",
    "    \n",
    "    # Extracting event titles\n",
    "    event_titles = soup.find_all('div', class_='event-content')\n",
    "    for title in event_titles:\n",
    "        event_details.append(title.text.strip())  # Append event title to the list\n",
    "    \n",
    "    return event_details\n",
    "\n",
    "# Extract event details\n",
    "event_details = extract_event_details(soup)\n",
    "\n",
    "# Print or process the extracted event details\n",
    "for event in event_details:\n",
    "    print(event)  # Print each event title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e6773",
   "metadata": {},
   "source": [
    "## Created a list called all_events which stores dictionaries in which Date Time Venue Title Artist_Name and Works are keys with their corresponding values from the website\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # Importing the re module for regular expression operations\n",
    "\n",
    "all_events = []  # List to store all extracted event details\n",
    "\n",
    "def extract_event_details(input_text):\n",
    "    \"\"\"\n",
    "    Extract event details from the input text using regular expressions.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The text containing event details.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted event details.\n",
    "    \"\"\"\n",
    "    def extract_text_between_keywords(text, keyword1, keyword2):\n",
    "        \"\"\"\n",
    "        Extract text between two keywords using regular expressions.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text.\n",
    "            keyword1 (str): The starting keyword.\n",
    "            keyword2 (str): The ending keyword.\n",
    "\n",
    "        Returns:\n",
    "            str: The text between the two keywords, or None if not found.\n",
    "        \"\"\"\n",
    "        pattern = re.compile(f'{re.escape(keyword1)}(.*?){re.escape(keyword2)}', re.DOTALL)\n",
    "        match = pattern.search(text)\n",
    "\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Define start and end keywords for extraction\n",
    "    start_keyword = \"Date and Venue\"\n",
    "    end_keyword = \"Program\"\n",
    "\n",
    "    # Extract different parts of the event details using the defined keywords\n",
    "    result = extract_text_between_keywords(input_text, start_keyword, end_keyword)\n",
    "    result_artist = extract_text_between_keywords(input_text, '|', 'Date and Venue')\n",
    "    result_works = extract_text_between_keywords(input_text, 'Program', 'Summer')\n",
    "    result_title = extract_text_between_keywords(input_text, '\\n', '|')  # Extracting title from the first line\n",
    "\n",
    "    if result:\n",
    "        # Split the result into tokens using '|' as delimiter\n",
    "        tokens = result.split('|')\n",
    "\n",
    "        # Remove leading and trailing whitespaces from each token\n",
    "        tokens = [token.strip() for token in tokens if token]\n",
    "\n",
    "        # Create the event dictionary\n",
    "        event_dict = {\n",
    "            \"Date\": tokens[0],\n",
    "            \"Time\": tokens[1],\n",
    "            \"Venue\": tokens[2],\n",
    "            \"Title\": result_title.splitlines()[0],  # Use the extracted title\n",
    "            \"Artist_Name\": result_artist,\n",
    "            \"Works\": result_works\n",
    "        }\n",
    "\n",
    "        return event_dict\n",
    "    else:\n",
    "\n",
    "        event_dict = {\n",
    "            \"Date\": \"\",\n",
    "            \"Time\": \"\",\n",
    "            \"Venue\": \"\",\n",
    "            \"Title\": \"\",  # Use the extracted title\n",
    "            \"Artist_Name\": \"\",\n",
    "            \"Works\": \"\"\n",
    "        }\n",
    "        return event_dict\n",
    "\n",
    "\n",
    "# Iterate over each event detail and extract its details\n",
    "for event in event_details:\n",
    "    # Extract event details using the defined function\n",
    "    event_dict = extract_event_details(event)\n",
    "    \n",
    "    # Append the extracted event details to the list\n",
    "    all_events.append(event_dict)\n",
    "    \n",
    "    # Print the extracted event details\n",
    "    print(event_dict)\n",
    "    print(len((event_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88c54f",
   "metadata": {},
   "source": [
    "### Printing all_events list od dictionaries which contains \"Date\",\"Time\",\"Venue\",\"Title\", \"Artist_Name\" and \"Works\" as key elements and corresponding values are fetched from the webscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch HTML content from the URL\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all <picture> elements with class 'clr-sec'\n",
    "li_elements = soup.find_all('picture', class_='clr-sec')\n",
    "\n",
    "# Filter out None values from all_events\n",
    "filtered_events = [event for event in all_events if event is not None]\n",
    "\n",
    "# Determine the minimum length to avoid IndexError\n",
    "min_length = min(len(filtered_events), len(li_elements))\n",
    "\n",
    "# Iterate over the minimum length and update image links\n",
    "for i in range(min_length):\n",
    "    try:\n",
    "        img_element = li_elements[i].find('source')  # Find <source> element within <picture>\n",
    "\n",
    "        if img_element:\n",
    "            img_path = \"https://www.lucernefestival.ch\" + img_element['srcset']  # Construct image URL\n",
    "            filtered_events[i]['ImageLink'] = img_path  # Update image link in event dictionary\n",
    "        else:\n",
    "            filtered_events[i]['ImageLink'] = 'NOT AVAILABLE'  # Set image link as 'NOT AVAILABLE' if <source> not found\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)  # Print any encountered errors\n",
    "\n",
    "\n",
    "\n",
    "# Update original all_events list with filtered_events\n",
    "all_events = filtered_events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc4d10",
   "metadata": {},
   "source": [
    "### printing all_events list of dictionaries which contains \"Date\",\"Time\",\"Venue\",\"Title\", \"Artist_Name\",\"Works\" with added \"ImageLink\" as a new key element and corresponding values are fetched from the webscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a175c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944dc252",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1f641",
   "metadata": {},
   "source": [
    "### I imported the psycopg2 library in Python to establish a connection with a PostgreSQL database. Then, I created a schema named CodingChallenge and a table named events within it, with columns for date, time, venue, artist_name, works, and image link. Finally, I inserted data from a list of dictionaries(all_events) containing event information into this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbc35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Connect to PostgreSQL database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"FutureDemand\",\n",
    "        user=\"postgres\",\n",
    "        password=\"Krishna7@\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    # Create a cursor object using a context manager\n",
    "    with conn.cursor() as cur:\n",
    "        # Create CodingChallenge schema\n",
    "        cur.execute(\"CREATE SCHEMA IF NOT EXISTS CodingChallenge\")\n",
    "\n",
    "        # Define schema and create events table\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS CodingChallenge.events (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                date TEXT,\n",
    "                time TEXT,\n",
    "                venue TEXT,\n",
    "                title TEXT,\n",
    "                artist_name TEXT,\n",
    "                works TEXT,\n",
    "                image_link TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "        # Delete all existing data from the events table\n",
    "        cur.execute(\"DELETE FROM CodingChallenge.events\")\n",
    "\n",
    "        # Iterate over all events and insert them into the PostgreSQL database\n",
    "        for event_data in all_events:\n",
    "            cur.execute(sql.SQL(\"\"\"\n",
    "                INSERT INTO CodingChallenge.events (date, time, venue, title, artist_name, works, image_link)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"), (\n",
    "                event_data[\"Date\"],\n",
    "                event_data[\"Time\"],\n",
    "                event_data[\"Venue\"],\n",
    "                event_data[\"Title\"],\n",
    "                event_data[\"Artist_Name\"],\n",
    "                event_data[\"Works\"],\n",
    "                event_data[\"ImageLink\"]\n",
    "            ))\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit()\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    # Close connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e029a",
   "metadata": {},
   "source": [
    "### Checking the Versions:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "print(bs4.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6776431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "print(psycopg2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db98f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "print(requests.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
